{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Polynomial & Spline Interpolation with Scikit Learn](https://scikit-learn.org/stable/auto_examples/linear_model/plot_polynomial_interpolation.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, SplineTransformer\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial & Spline Approximation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \"\"\"Defines a function to approximate.\n",
    "\n",
    "    Args:\n",
    "        x (ndarray): This is the list of points that will seed the\n",
    "                     function.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: This is a list of points that are representative of the\n",
    "                 approximated function.\n",
    "    \"\"\"\n",
    "    return x * np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = np.linspace(-1, 11, 100)\n",
    "x_train = np.linspace(0, 10, 100)\n",
    "rng = np.random.RandomState(0)\n",
    "x_train = np.sort(rng.choice(x_train, size=20, replace=False))\n",
    "y_train = f(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train[:, np.newaxis]\n",
    "X_plot = x_plot[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Function\n",
    "lw = 2\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_prop_cycle(\n",
    "    color=[\"black\", \"teal\", \"yellowgreen\", \"gold\", \"darkorange\", \"tomato\"]\n",
    ")\n",
    "ax.plot(x_plot, f(x_plot), linewidth=lw, label=\"ground truth\")\n",
    "\n",
    "# plot training points\n",
    "ax.scatter(x_train, y_train, label=\"training points\")\n",
    "\n",
    "# polynomial features\n",
    "for degree in [3, 4, 5]:\n",
    "    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=1e-3))\n",
    "    model.fit(X_train, y_train)\n",
    "    y_plot = model.predict(X_plot)\n",
    "    ax.plot(x_plot, y_plot, label=f\"degree {degree}\")\n",
    "\n",
    "# B-spline with 4 + 3 - 1 = 6 basis functions\n",
    "model = make_pipeline(SplineTransformer(n_knots=4, degree=3), Ridge(alpha=1e-3))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_plot = model.predict(X_plot)\n",
    "ax.plot(x_plot, y_plot, label=\"B-spline\")\n",
    "ax.legend(loc=\"lower center\")\n",
    "ax.set_ylim(-20, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Periodic Splines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    \"\"\"Function to be approximated by periodic spline interpolation.\"\"\"\n",
    "    return np.sin(x) - 0.7 * np.cos(x * 3)\n",
    "\n",
    "\n",
    "y_train = g(x_train)\n",
    "\n",
    "# Extend the test data into the future:\n",
    "x_plot_ext = np.linspace(-1, 21, 200)\n",
    "x_plot_ext = x_plot_ext[:, np.newaxis]\n",
    "\n",
    "lw = 2\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_prop_cycle(color=[\"black\", \"tomato\", \"teal\"])\n",
    "ax.plot(x_plot_ext, g(x_plot_ext), linewidth=lw, label=\"ground truth\")\n",
    "ax.scatter(x_train, y_train, label=\"training points\")\n",
    "\n",
    "for transformer, label in [\n",
    "    (SplineTransformer(degree=3, n_knots=10), \"spline\"),\n",
    "    (\n",
    "        SplineTransformer(\n",
    "            degree=3,\n",
    "            knots=np.linspace(0, 2 * np.pi, 10)[:, None],\n",
    "            extrapolation=\"periodic\",\n",
    "        ),\n",
    "        \"periodic spline\",\n",
    "    ),\n",
    "]:\n",
    "    model = make_pipeline(transformer, Ridge(alpha=1e-3))\n",
    "    model.fit(X_train, y_train)\n",
    "    y_plot_ext = model.predict(x_plot_ext)\n",
    "    ax.plot(x_plot_ext, y_plot_ext, label=label)\n",
    "\n",
    "ax.legend()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuralink Compression Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "from scipy.signal import detrend, lfilter, butter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_noise_floor(amplitude_array, window_size=10):\n",
    "    \"\"\"This function will estimate the noise floor. The amplitude array\n",
    "    must be at least of length of the window size or a single value.\n",
    "\n",
    "    Args:\n",
    "        amplitude_array (numpy.ndarray): Array of amplitudes with which\n",
    "                                         to derive the noise floor.\n",
    "\n",
    "        window_size (int, optional): This is the width of the window\n",
    "                                     used to calculate a rolling median\n",
    "                                     average.\n",
    "\n",
    "    Return:\n",
    "        noise_floor_estimate (np.ndarray): This is the estimate of the\n",
    "                                           noise floor.\n",
    "    \"\"\"\n",
    "    if len(amplitude_array) == 0:\n",
    "        raise ValueError(\"Length of amplitude array must be greater than 0\")\n",
    "    elif len(amplitude_array) == 1:\n",
    "        noise_floor_estimate = np.array(\n",
    "            [np.sqrt(np.abs(np.float64(amplitude_array[0])) ** 2)]\n",
    "        )\n",
    "        return noise_floor_estimate\n",
    "    else:\n",
    "        if len(amplitude_array) < window_size:\n",
    "            window_size = len(amplitude_array)\n",
    "        power_of_filtered_data = np.abs(np.float64(amplitude_array) ** 2)\n",
    "\n",
    "        rolling_median_array = []\n",
    "        for index in range(0, len(power_of_filtered_data), 1):\n",
    "            current_median = np.median(\n",
    "                power_of_filtered_data[index : index + window_size]\n",
    "            )\n",
    "            rolling_median_array.append(current_median)\n",
    "\n",
    "        rolling_median_array = np.array(rolling_median_array)\n",
    "\n",
    "        noise_floor_estimate = np.sqrt(rolling_median_array)\n",
    "\n",
    "        return noise_floor_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_potential_initial_spikes(amplitude_array, return_local_maximum=True):\n",
    "    \"\"\"This function searches for peak amplitudes that may be initial\n",
    "    neural spiking activity. This function is extended to filter the\n",
    "    local maximum or minimum spiking activity. This is used to identify\n",
    "    second or third spikes as well.\n",
    "\n",
    "    Args:\n",
    "        amplitude_array (numpy.ndarray): This contains an array of\n",
    "                                         amplitudes of neural signal.\n",
    "        return_local_maximum (bool, optional): This defines the logic of\n",
    "                                               the returned values. If\n",
    "                                               True, the values will be\n",
    "                                               the local maximums of the\n",
    "                                               amplitude array. When\n",
    "                                               False,the returned list\n",
    "                                               will be local minimums.\n",
    "\n",
    "    Returns:\n",
    "        list: This is a list of boolean values that indicate whether a\n",
    "        point is a local maximum with respect to the next and previous\n",
    "        amplitudes. If return_local_maximum is set to False, then the\n",
    "        returned list contains information of local minimums instead.\n",
    "    \"\"\"\n",
    "    if len(amplitude_array) < 3:\n",
    "        if len(amplitude_array) == 0:\n",
    "            return ValueError(\"Length of amplitude array must be greater than 0\")\n",
    "        elif len(amplitude_array) == 1:\n",
    "            return [True]\n",
    "        else:\n",
    "            if return_local_maximum:\n",
    "                if amplitude_array[0] < amplitude_array[1]:\n",
    "                    return [False, True]\n",
    "                else:\n",
    "                    return [True, False]\n",
    "            else:\n",
    "                if amplitude_array[0] < amplitude_array[1]:\n",
    "                    return [True, False]\n",
    "                else:\n",
    "                    return [False, True]\n",
    "    else:\n",
    "        if return_local_maximum:\n",
    "            local_maximum_list = []\n",
    "            for idx, val in enumerate(amplitude_array[0:-1]):\n",
    "                if idx == 0:\n",
    "                    if amplitude_array[idx + 1] < val:\n",
    "                        local_maximum_list.append(True)\n",
    "                    else:\n",
    "                        local_maximum_list.append(False)\n",
    "                    continue\n",
    "                if (amplitude_array[idx - 1] < val) and (\n",
    "                    val > amplitude_array[idx + 1]\n",
    "                ):\n",
    "                    local_maximum_list.append(True)\n",
    "                else:\n",
    "                    local_maximum_list.append(False)\n",
    "            if amplitude_array[-1] > amplitude_array[-2]:\n",
    "                local_maximum_list.append(True)\n",
    "            else:\n",
    "                local_maximum_list.append(False)\n",
    "            return local_maximum_list\n",
    "        else:\n",
    "            local_minimum_list = []\n",
    "            for idx, val in enumerate(amplitude_array[0:-1]):\n",
    "                if idx == 0:\n",
    "                    if amplitude_array[idx + 1] > val:\n",
    "                        local_minimum_list.append(True)\n",
    "                    else:\n",
    "                        local_minimum_list.append(False)\n",
    "                    continue\n",
    "                if (amplitude_array[idx - 1] > val) and (\n",
    "                    val < amplitude_array[idx + 1]\n",
    "                ):\n",
    "                    local_minimum_list.append(True)\n",
    "                else:\n",
    "                    local_minimum_list.append(False)\n",
    "            if amplitude_array[-1] < amplitude_array[-2]:\n",
    "                local_minimum_list.append(True)\n",
    "            else:\n",
    "                local_minimum_list.append(False)\n",
    "            return local_minimum_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_neural_spikes(t, neural_data):\n",
    "    \"\"\"This function detects spikes in real-time.\n",
    "    It returns an array of spikes at specific times and amplitudes with\n",
    "    zeroed out noise.\n",
    "\n",
    "    Args:\n",
    "        t (array): This is the array of values that indicate the time of\n",
    "                   each point in the neural_data array.\n",
    "        neural_data (array): This is the array of amplitudes for each\n",
    "                             point of time of the neural data.\n",
    "\n",
    "    Returns:\n",
    "        (list): This is the array inclusive of amplitudes of spikes at\n",
    "                each specific point in the initial time array. Non-spike\n",
    "                points have been replaced with amplitudes of zero value.\n",
    "    \"\"\"\n",
    "    noise_floor_window = 5\n",
    "    initial_first_point_of_spike_detected = False\n",
    "    second_point_of_spike_detected = False\n",
    "    third_point_of_spike_detected = False\n",
    "    spike_train_time_index_list = []\n",
    "\n",
    "    for current_time_index, time in enumerate(t):\n",
    "        # Estimate the noise floor\n",
    "        if current_time_index < noise_floor_window:\n",
    "            current_noise_floor_estimate_list = estimate_noise_floor(\n",
    "                [neural_data[current_time_index]]\n",
    "            )\n",
    "        else:\n",
    "            current_noise_floor_estimate_list = estimate_noise_floor(\n",
    "                neural_data[\n",
    "                    current_time_index - noise_floor_window : current_time_index\n",
    "                ],\n",
    "                window_size=noise_floor_window,\n",
    "            )\n",
    "\n",
    "        current_noise_floor_estimate = current_noise_floor_estimate_list[0]\n",
    "        current_noise_floor_estimate_inverse = -(current_noise_floor_estimate)\n",
    "\n",
    "        # Detect Initial First Point\n",
    "        if initial_first_point_of_spike_detected == False:\n",
    "            if current_time_index == 0:\n",
    "                local_maximum_list_of_current_time_index = (\n",
    "                    identify_potential_initial_spikes(\n",
    "                        neural_data[current_time_index : current_time_index + 1]\n",
    "                    )\n",
    "                )\n",
    "                is_current_time_index_local_maximum = (\n",
    "                    local_maximum_list_of_current_time_index[0]\n",
    "                )\n",
    "            else:\n",
    "                local_maximum_list_of_current_time_index = (\n",
    "                    identify_potential_initial_spikes(\n",
    "                        neural_data[current_time_index - 1 : current_time_index + 2]\n",
    "                    )\n",
    "                )\n",
    "                is_current_time_index_local_maximum = (\n",
    "                    local_maximum_list_of_current_time_index[1]\n",
    "                )\n",
    "\n",
    "            if is_current_time_index_local_maximum == True:\n",
    "                # First Point Potentially Identified\n",
    "                initial_first_point_of_spike_detected = True\n",
    "                spike_time_index_first_point = current_time_index\n",
    "        elif (\n",
    "            second_point_of_spike_detected == False\n",
    "            and initial_first_point_of_spike_detected == True\n",
    "        ):\n",
    "            # Detect Second Point\n",
    "            local_minimum_list_of_current_time_index = (\n",
    "                identify_potential_initial_spikes(\n",
    "                    neural_data[current_time_index - 1 : current_time_index + 2],\n",
    "                    return_local_maximum=False,\n",
    "                )\n",
    "            )\n",
    "            is_current_time_index_local_minimum = (\n",
    "                local_minimum_list_of_current_time_index[1]\n",
    "            )\n",
    "            if is_current_time_index_local_minimum == True:\n",
    "                if (\n",
    "                    neural_data[current_time_index]\n",
    "                    < current_noise_floor_estimate_inverse\n",
    "                ):\n",
    "                    # Second Point Found\n",
    "                    spike_time_index_list_first_to_second_points = np.arange(\n",
    "                        start=spike_time_index_first_point,\n",
    "                        stop=current_time_index,\n",
    "                        step=1,\n",
    "                    )\n",
    "                    spike_time_index_second_point = current_time_index\n",
    "                    second_point_of_spike_detected = True\n",
    "                else:\n",
    "                    initial_first_point_of_spike_detected = False\n",
    "        elif (\n",
    "            initial_first_point_of_spike_detected == True\n",
    "            and second_point_of_spike_detected == True\n",
    "            and third_point_of_spike_detected == False\n",
    "        ):\n",
    "            # Detect Third Point\n",
    "            local_maximum_list_of_current_time_index = (\n",
    "                identify_potential_initial_spikes(\n",
    "                    neural_data[current_time_index - 1 : current_time_index + 2]\n",
    "                )\n",
    "            )\n",
    "            is_current_time_index_local_maximum = (\n",
    "                local_maximum_list_of_current_time_index[1]\n",
    "            )\n",
    "            if is_current_time_index_local_maximum == True:\n",
    "                if neural_data[current_time_index] > current_noise_floor_estimate:\n",
    "                    # Third Point Found\n",
    "                    spike_time_index_list_second_to_third_points = np.arange(\n",
    "                        spike_time_index_second_point, current_time_index + 1, step=1\n",
    "                    )\n",
    "                    third_point_of_spike_detected = True\n",
    "                    time_index_of_most_recent_third_spike = current_time_index\n",
    "                else:\n",
    "                    initial_first_point_of_spike_detected = True\n",
    "                    second_point_of_spike_detected = False\n",
    "                    spike_time_index_first_point = current_time_index\n",
    "        elif (\n",
    "            initial_first_point_of_spike_detected == True\n",
    "            and second_point_of_spike_detected == True\n",
    "            and third_point_of_spike_detected == True\n",
    "        ):\n",
    "            # Detect Fourth Point\n",
    "            if neural_data[current_time_index] < 0:\n",
    "                time_index_of_most_recent_fourth_spike_point = current_time_index\n",
    "                spike_time_index_list_third_to_fourth_points = np.arange(\n",
    "                    time_index_of_most_recent_third_spike,\n",
    "                    time_index_of_most_recent_fourth_spike_point + 1,\n",
    "                    step=1,\n",
    "                )\n",
    "                spike_time_index_list = np.concatenate(\n",
    "                    [\n",
    "                        spike_time_index_list_first_to_second_points,\n",
    "                        spike_time_index_list_second_to_third_points,\n",
    "                        spike_time_index_list_third_to_fourth_points,\n",
    "                    ]\n",
    "                )\n",
    "                spike_train_time_index_list.append(spike_time_index_list)\n",
    "\n",
    "                initial_first_point_of_spike_detected = False\n",
    "                second_point_of_spike_detected = False\n",
    "                third_point_of_spike_detected = False\n",
    "        else:\n",
    "            raise ValueError(\"Error in Spike Detection State\")\n",
    "\n",
    "    return spike_train_time_index_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Neural Spikes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../data/\"\n",
    "data_file_l = glob(data_dir + \"*.wav\")\n",
    "current_data_file = data_file_l[0]\n",
    "current_data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate, raw_neural_data = wavfile.read(current_data_file)\n",
    "time_array_length = len(raw_neural_data) / sample_rate\n",
    "time_array = np.arange(start=0, stop=time_array_length, step=(1 / sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detrend\n",
    "detrended_neural_data = np.int16(detrend(raw_neural_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyq = sample_rate // 2\n",
    "low_cutoff_freq = 500\n",
    "high_cutoff_freq = 5000\n",
    "low = low_cutoff_freq / nyq\n",
    "high = high_cutoff_freq / nyq\n",
    "order = 4\n",
    "numerator, denominator = butter(order, [low, high], btype=\"band\")\n",
    "\n",
    "filtered_data_bandpass = np.int16(\n",
    "    lfilter(numerator, denominator, detrended_neural_data)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_train_time_index_list = detect_neural_spikes(time_array, filtered_data_bandpass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(filtered_data_bandpass, columns=[\"Amplitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(time_array, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.name = \"Time [S]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENT_SPIKE = len(spike_train_time_index_list) - 1\n",
    "CURRENT_SPIKE = 1\n",
    "plt.title(f\"Detected Spike Number: {CURRENT_SPIKE}\")\n",
    "df[\"Amplitude\"].iloc[spike_train_time_index_list[CURRENT_SPIKE]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Amplitude\"].iloc[spike_train_time_index_list[CURRENT_SPIKE]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_encoding_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
