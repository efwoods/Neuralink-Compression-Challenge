{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spike Detection Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import IPython.display as ipd\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import lfilter, butter\n",
    "from collections import deque\n",
    "import sys\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_potential_initial_spikes(amplitude_array, return_local_maximum=True):\n",
    "    \"\"\"This function searches for peak amplitudes that may be initial\n",
    "    neural spiking activity. This function is extended to filter the\n",
    "    local maximum or minimum spiking activity. This is used to identify\n",
    "    second or third spikes as well.\n",
    "\n",
    "    Args:\n",
    "        amplitude_array (numpy.ndarray): This contains an array of\n",
    "                                         amplitudes of neural signal.\n",
    "        return_local_maximum (bool, optional): This defines the logic of\n",
    "                                               the returned values. If\n",
    "                                               True, the values will be\n",
    "                                               the local maximums of the\n",
    "                                               amplitude array. When\n",
    "                                               False,the returned list\n",
    "                                               will be local minimums.\n",
    "\n",
    "    Returns:\n",
    "        list: This is a list of boolean values that indicate whether a\n",
    "        point is a local maximum with respect to the next and previous\n",
    "        amplitudes. If return_local_maximum is set to False, then the\n",
    "        returned list contains information of local minimums instead.\n",
    "    \"\"\"\n",
    "    if len(amplitude_array) < 3:\n",
    "        if len(amplitude_array) == 0:\n",
    "            return ValueError(\"Length of amplitude array must be greater than 0\")\n",
    "        elif len(amplitude_array) == 1:\n",
    "            return [True]\n",
    "        else:\n",
    "            if return_local_maximum:\n",
    "                if amplitude_array[0] < amplitude_array[1]:\n",
    "                    return [False, True]\n",
    "                else:\n",
    "                    return [True, False]\n",
    "            else:\n",
    "                if amplitude_array[0] < amplitude_array[1]:\n",
    "                    return [True, False]\n",
    "                else:\n",
    "                    return [False, True]\n",
    "    else:\n",
    "        if return_local_maximum:\n",
    "            local_maximum_list = []\n",
    "            for idx, val in enumerate(amplitude_array[0:-1]):\n",
    "                if idx == 0:\n",
    "                    if amplitude_array[idx + 1] < val:\n",
    "                        local_maximum_list.append(True)\n",
    "                    else:\n",
    "                        local_maximum_list.append(False)\n",
    "                    continue\n",
    "                if (amplitude_array[idx - 1] < val) and (\n",
    "                    val > amplitude_array[idx + 1]\n",
    "                ):\n",
    "                    local_maximum_list.append(True)\n",
    "                else:\n",
    "                    local_maximum_list.append(False)\n",
    "            if amplitude_array[-1] > amplitude_array[-2]:\n",
    "                local_maximum_list.append(True)\n",
    "            else:\n",
    "                local_maximum_list.append(False)\n",
    "            return local_maximum_list\n",
    "        else:\n",
    "            local_minimum_list = []\n",
    "            for idx, val in enumerate(amplitude_array[0:-1]):\n",
    "                if idx == 0:\n",
    "                    if amplitude_array[idx + 1] > val:\n",
    "                        local_minimum_list.append(True)\n",
    "                    else:\n",
    "                        local_minimum_list.append(False)\n",
    "                    continue\n",
    "                if (amplitude_array[idx - 1] > val) and (\n",
    "                    val < amplitude_array[idx + 1]\n",
    "                ):\n",
    "                    local_minimum_list.append(True)\n",
    "                else:\n",
    "                    local_minimum_list.append(False)\n",
    "            if amplitude_array[-1] < amplitude_array[-2]:\n",
    "                local_minimum_list.append(True)\n",
    "            else:\n",
    "                local_minimum_list.append(False)\n",
    "            return local_minimum_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_noise_floor(amplitude_array, window_size=10):\n",
    "    \"\"\"This function will estimate the noise floor. The amplitude array\n",
    "    must be at least of length of the window size or a single value.\n",
    "\n",
    "    Args:\n",
    "        amplitude_array (numpy.ndarray): Array of amplitudes with which\n",
    "                                         to derive the noise floor.\n",
    "\n",
    "        window_size (int, optional): This is the width of the window\n",
    "                                     used to calculate a rolling median\n",
    "                                     average.\n",
    "\n",
    "    Return:\n",
    "        noise_floor_estimate (np.ndarray): This is the estimate of the\n",
    "                                           noise floor.\n",
    "    \"\"\"\n",
    "    if len(amplitude_array) == 0:\n",
    "        raise ValueError(\"Length of amplitude array must be greater than 0\")\n",
    "    elif len(amplitude_array) == 1:\n",
    "        noise_floor_estimate = np.array(\n",
    "            [np.sqrt(np.abs(np.float64(amplitude_array[0])) ** 2)]\n",
    "        )\n",
    "        return noise_floor_estimate\n",
    "    else:\n",
    "        if len(amplitude_array) < window_size:\n",
    "            window_size = len(amplitude_array)\n",
    "        power_of_filtered_data = np.abs(np.float64(amplitude_array) ** 2)\n",
    "\n",
    "        rolling_median_array = []\n",
    "        for index in range(0, len(power_of_filtered_data), 1):\n",
    "            current_median = np.median(\n",
    "                power_of_filtered_data[index : index + window_size]\n",
    "            )\n",
    "            rolling_median_array.append(current_median)\n",
    "\n",
    "        rolling_median_array = np.array(rolling_median_array)\n",
    "\n",
    "        noise_floor_estimate = np.sqrt(rolling_median_array)\n",
    "\n",
    "        return noise_floor_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_neural_spikes(t, neural_data):\n",
    "    \"\"\"This function detects spikes in real-time.\n",
    "    It returns an array of spikes at specific times and amplitudes with\n",
    "    zeroed out noise.\n",
    "\n",
    "    Args:\n",
    "        t (array): This is the array of values that indicate the time of\n",
    "                   each point in the neural_data array.\n",
    "        neural_data (array): This is the array of amplitudes for each\n",
    "                             point of time of the neural data.\n",
    "\n",
    "    Returns:\n",
    "        (list): This is the array inclusive of amplitudes of spikes at\n",
    "                each specific point in the initial time array. Non-spike\n",
    "                points have been replaced with amplitudes of zero value.\n",
    "    \"\"\"\n",
    "    noise_floor_window = 5\n",
    "    initial_first_point_of_spike_detected = False\n",
    "    second_point_of_spike_detected = False\n",
    "    third_point_of_spike_detected = False\n",
    "    spike_train_time_index_list = []\n",
    "\n",
    "    for current_time_index, time in enumerate(t):\n",
    "        # Estimate the noise floor\n",
    "        if current_time_index < noise_floor_window:\n",
    "            current_noise_floor_estimate_list = estimate_noise_floor(\n",
    "                [neural_data[current_time_index]]\n",
    "            )\n",
    "        else:\n",
    "            current_noise_floor_estimate_list = estimate_noise_floor(\n",
    "                neural_data[\n",
    "                    current_time_index - noise_floor_window : current_time_index\n",
    "                ],\n",
    "                window_size=noise_floor_window,\n",
    "            )\n",
    "\n",
    "        current_noise_floor_estimate = current_noise_floor_estimate_list[0]\n",
    "        current_noise_floor_estimate_inverse = -(current_noise_floor_estimate)\n",
    "\n",
    "        # Detect Initial First Point\n",
    "        if initial_first_point_of_spike_detected == False:\n",
    "            if current_time_index == 0:\n",
    "                local_maximum_list_of_current_time_index = (\n",
    "                    identify_potential_initial_spikes(\n",
    "                        neural_data[current_time_index : current_time_index + 1]\n",
    "                    )\n",
    "                )\n",
    "                is_current_time_index_local_maximum = (\n",
    "                    local_maximum_list_of_current_time_index[0]\n",
    "                )\n",
    "            else:\n",
    "                local_maximum_list_of_current_time_index = (\n",
    "                    identify_potential_initial_spikes(\n",
    "                        neural_data[current_time_index - 1 : current_time_index + 2]\n",
    "                    )\n",
    "                )\n",
    "                is_current_time_index_local_maximum = (\n",
    "                    local_maximum_list_of_current_time_index[1]\n",
    "                )\n",
    "\n",
    "            if is_current_time_index_local_maximum == True:\n",
    "                # First Point Potentially Identified\n",
    "                initial_first_point_of_spike_detected = True\n",
    "                spike_time_index_first_point = current_time_index\n",
    "        elif (\n",
    "            second_point_of_spike_detected == False\n",
    "            and initial_first_point_of_spike_detected == True\n",
    "        ):\n",
    "            # Detect Second Point\n",
    "            local_minimum_list_of_current_time_index = (\n",
    "                identify_potential_initial_spikes(\n",
    "                    neural_data[current_time_index - 1 : current_time_index + 2],\n",
    "                    return_local_maximum=False,\n",
    "                )\n",
    "            )\n",
    "            is_current_time_index_local_minimum = (\n",
    "                local_minimum_list_of_current_time_index[1]\n",
    "            )\n",
    "            if is_current_time_index_local_minimum == True:\n",
    "                if (\n",
    "                    neural_data[current_time_index]\n",
    "                    < current_noise_floor_estimate_inverse\n",
    "                ):\n",
    "                    # Second Point Found\n",
    "                    spike_time_index_list_first_to_second_points = np.arange(\n",
    "                        start=spike_time_index_first_point,\n",
    "                        stop=current_time_index,\n",
    "                        step=1,\n",
    "                    )\n",
    "                    spike_time_index_second_point = current_time_index\n",
    "                    second_point_of_spike_detected = True\n",
    "                else:\n",
    "                    initial_first_point_of_spike_detected = False\n",
    "        elif (\n",
    "            initial_first_point_of_spike_detected == True\n",
    "            and second_point_of_spike_detected == True\n",
    "            and third_point_of_spike_detected == False\n",
    "        ):\n",
    "            # Detect Third Point\n",
    "            local_maximum_list_of_current_time_index = (\n",
    "                identify_potential_initial_spikes(\n",
    "                    neural_data[current_time_index - 1 : current_time_index + 2]\n",
    "                )\n",
    "            )\n",
    "            is_current_time_index_local_maximum = (\n",
    "                local_maximum_list_of_current_time_index[1]\n",
    "            )\n",
    "            if is_current_time_index_local_maximum == True:\n",
    "                if neural_data[current_time_index] > current_noise_floor_estimate:\n",
    "                    # Third Point Found\n",
    "                    spike_time_index_list_second_to_third_points = np.arange(\n",
    "                        spike_time_index_second_point,\n",
    "                        current_time_index,\n",
    "                        step=1,\n",
    "                    )\n",
    "                    third_point_of_spike_detected = True\n",
    "                    time_index_of_most_recent_third_spike = current_time_index\n",
    "                else:\n",
    "                    initial_first_point_of_spike_detected = True\n",
    "                    second_point_of_spike_detected = False\n",
    "                    spike_time_index_first_point = current_time_index\n",
    "        elif (\n",
    "            initial_first_point_of_spike_detected == True\n",
    "            and second_point_of_spike_detected == True\n",
    "            and third_point_of_spike_detected == True\n",
    "        ):\n",
    "            # Detect Fourth Point\n",
    "            if neural_data[current_time_index] < 0:\n",
    "                time_index_of_most_recent_fourth_spike_point = current_time_index\n",
    "                spike_time_index_list_third_to_fourth_points = np.arange(\n",
    "                    time_index_of_most_recent_third_spike,\n",
    "                    time_index_of_most_recent_fourth_spike_point\n",
    "                    + 1,  # include the fourth detected point\n",
    "                    step=1,\n",
    "                )\n",
    "                spike_time_index_list = np.concatenate(\n",
    "                    [\n",
    "                        spike_time_index_list_first_to_second_points,\n",
    "                        spike_time_index_list_second_to_third_points,\n",
    "                        spike_time_index_list_third_to_fourth_points,\n",
    "                    ]\n",
    "                )\n",
    "                spike_train_time_index_list.append(spike_time_index_list)\n",
    "\n",
    "                initial_first_point_of_spike_detected = False\n",
    "                second_point_of_spike_detected = False\n",
    "                third_point_of_spike_detected = False\n",
    "        else:\n",
    "            raise ValueError(\"Error in Spike Detection State\")\n",
    "\n",
    "    return spike_train_time_index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoded_data(\n",
    "    sample_rate,\n",
    "    number_of_samples,\n",
    "    spike_train_time_index_list,\n",
    "    neural_data,\n",
    "):\n",
    "    \"\"\"This function creates an encoded version of the initial data.\n",
    "\n",
    "    Args:\n",
    "        spike_train_time_index_list (list): This is the list of array of\n",
    "                                            floats that indicate indices\n",
    "                                            of amplitudes.\n",
    "        neural_data (array): These are the amplitudes of all values in\n",
    "                             the dataset.\n",
    "        time_array_of_neural_data (array): These are the points of time\n",
    "                                           of the dataset.\n",
    "        sample_rate (int): This is the sample rate of the data. The\n",
    "                              samples are equidistant depending upon the\n",
    "                              sampling frequency as calculated from the\n",
    "                              inverse of the sample rate.\n",
    "        number_of_samples (int): This is the total number of samples in\n",
    "                                 the dataset.\n",
    "\n",
    "    Returns:\n",
    "        encoded_data (list): This is the encoded data. This encoded data\n",
    "                             has the sample rate, the number of samples,\n",
    "                             the initial start time index of the first\n",
    "                             amplitude, and the information of the\n",
    "                             amplitudes of the detected eeg spikes.\n",
    "                             This pattern of the initial time index\n",
    "                             of the first amplitude, represented as an\n",
    "                             int, followed by the array of amplitude\n",
    "                             values at each sample is repeated for each\n",
    "                             detected spike. It is implied that the\n",
    "                             samples are equidistant depending upon\n",
    "                             the sampling frequency as calculated from\n",
    "                             the inverse of the sample rate, that the\n",
    "                             length of time of the entire data is\n",
    "                             inferred from the number of samples divided\n",
    "                             by the sample rate, and all amplitudes at\n",
    "                             samples not explicitly defined are to be\n",
    "                             considered noise and are therefore set to\n",
    "                             zero to reduce size while retaining\n",
    "                             information. The time of each amplitude is\n",
    "                             calculated as the division of the starting\n",
    "                             time index plus the current position of\n",
    "                             each amplitude by the current posigion in\n",
    "                             the zero-based amplitude array by the\n",
    "                             sample rate.\n",
    "    \"\"\"\n",
    "    encoded_data = []\n",
    "    encoded_data.append(sample_rate)\n",
    "    encoded_data.append(number_of_samples)\n",
    "    for spike_train_index in range(0, len(spike_train_time_index_list)):\n",
    "        index = np.int16(spike_train_time_index_list[spike_train_index][0])\n",
    "        if index < 0:\n",
    "            print(index)\n",
    "        encoded_data.append(np.int64(spike_train_time_index_list[spike_train_index][0]))\n",
    "        encoded_data.append(neural_data[spike_train_time_index_list[spike_train_index]])\n",
    "\n",
    "    return encoded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/\"\n",
    "data_file_list = glob(data_dir + \"*.wav\")\n",
    "current_data_file = data_file_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(current_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate, raw_neural_data = wavfile.read(current_data_file)\n",
    "time_array_length = len(raw_neural_data) / sample_rate\n",
    "time_array = np.arange(start=0, stop=time_array_length, step=(1 / sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas Implementation of Graphing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_neural_data_df = pd.DataFrame(raw_neural_data, columns=[\"Amplitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_neural_data_df.set_index(time_array, inplace=True)\n",
    "raw_neural_data_df.index.name = \"Time [s]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SCALE = 0.1\n",
    "WINDOW_START = 100\n",
    "WINDOW_SIZE = 100\n",
    "WINDOW_SHIFT = 40\n",
    "\n",
    "raw_neural_data_df.iloc[\n",
    "    int(WINDOW_SCALE * (WINDOW_START + WINDOW_SHIFT)) : int(\n",
    "        WINDOW_SCALE * (WINDOW_START + WINDOW_SIZE + WINDOW_SHIFT)\n",
    "    )\n",
    "].plot(linewidth=0.5)\n",
    "plt.axhline(y=0, color=\"blue\")\n",
    "plt.title(\"Raw Neural Signal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot of Raw Neural Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(time_array, raw_neural_data, linewidth=0.5)\n",
    "plt.title(\"Raw Neural Data\")\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend([\"Raw Neural Signal\"])\n",
    "plt.grid(True)\n",
    "plt.axhline(y=0, color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_neural_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the Signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detrend & Normalize the Signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detrend\n",
    "detrended_neural_data = np.int16(scipy.signal.detrend(raw_neural_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time_array, detrended_neural_data)\n",
    "plt.title(\"Normalized & Detrended Neural Data\")\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend([\"Normalized & Detrended Neural Signal\"])\n",
    "plt.axhline(y=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Band-Pass Filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyq = sample_rate // 2\n",
    "low_cutoff_freq = 500\n",
    "high_cutoff_freq = 5000\n",
    "low = low_cutoff_freq / nyq\n",
    "high = high_cutoff_freq / nyq\n",
    "order = 4\n",
    "numerator, denominator = butter(order, [low, high], btype=\"band\")\n",
    "\n",
    "filtered_data_bandpass = np.int16(\n",
    "    lfilter(numerator, denominator, detrended_neural_data)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Neural Spikes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_train_time_index_list = detect_neural_spikes(time_array, filtered_data_bandpass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_bandpass_fft = np.fft.fft(filtered_data_bandpass)\n",
    "freq_bins_filtered_data_bandpass_fft = np.arange(\n",
    "    0, sample_rate / 2, step=(sample_rate / len(filtered_data_bandpass_fft))\n",
    ")\n",
    "\n",
    "# Time Domain Plot\n",
    "plt.figure(figsize=(36, 4))\n",
    "plt.plot(\n",
    "    time_array[0:3000],\n",
    "    filtered_data_bandpass[0:3000],\n",
    "    color=list(mcolors.TABLEAU_COLORS.keys())[2],\n",
    "    linewidth=1,\n",
    "    label=\"Bandpass Filtered Data\",\n",
    ")\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"Bandpass Filtered Data\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# FFT Plot\n",
    "plt.figure(figsize=(12, 4))\n",
    "if len(freq_bins_filtered_data_bandpass_fft) == (len(filtered_data_bandpass_fft) // 2):\n",
    "    fft_slice = len(freq_bins_filtered_data_bandpass_fft)\n",
    "else:\n",
    "    fft_slice = len(freq_bins_filtered_data_bandpass_fft) - 1\n",
    "plt.plot(\n",
    "    freq_bins_filtered_data_bandpass_fft[0:fft_slice],\n",
    "    np.abs(filtered_data_bandpass_fft[0 : len(filtered_data_bandpass_fft) // 2]),\n",
    "    color=list(mcolors.TABLEAU_COLORS.keys())[2],\n",
    "    label=\"FFT of the Low & High Pass Filtered Signal\",\n",
    "    linewidth=0.1,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Frequency [Hz]\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"Magnitude-Frequency Plot Comparison of Bandpass Filtered Neural Data\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Potential First Spike Points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying Potential First Spike Points\n",
    "local_maximum_list = identify_potential_initial_spikes(filtered_data_bandpass)\n",
    "\n",
    "# Identifying Noise Floor Estimate\n",
    "\n",
    "# Simulating Real-Time Detection of the Noise Floor & its Inverse\n",
    "noise_floor_estimate = []\n",
    "noise_floor_estimate_inverse = []\n",
    "noise_floor_window = 5\n",
    "\n",
    "for current_time_index, time in enumerate(time_array):\n",
    "    # Estimate the noise floor\n",
    "    if current_time_index < noise_floor_window:\n",
    "        current_noise_floor_estimate_list = estimate_noise_floor(\n",
    "            [filtered_data_bandpass[current_time_index]]\n",
    "        )\n",
    "    else:\n",
    "        current_noise_floor_estimate_list = estimate_noise_floor(\n",
    "            filtered_data_bandpass[\n",
    "                current_time_index - noise_floor_window : current_time_index\n",
    "            ],\n",
    "            window_size=noise_floor_window,\n",
    "        )\n",
    "    current_noise_floor_estimate = current_noise_floor_estimate_list[0]\n",
    "    noise_floor_estimate.append(current_noise_floor_estimate)\n",
    "\n",
    "    current_noise_floor_estimate_inverse = -(current_noise_floor_estimate)\n",
    "    noise_floor_estimate_inverse.append(current_noise_floor_estimate_inverse)\n",
    "\n",
    "# Time Domain Plot\n",
    "# WINDOW_SIZE = len(time_array)\n",
    "PLOT_WINDOW_SIZE = 500\n",
    "\n",
    "# Subsets\n",
    "time_array_subset = time_array[0:PLOT_WINDOW_SIZE]\n",
    "filtered_data_bandpass_subset = filtered_data_bandpass[0:PLOT_WINDOW_SIZE]\n",
    "noise_floor_estimate_subset = noise_floor_estimate[0:PLOT_WINDOW_SIZE]\n",
    "noise_floor_estimate_inverse_subset = noise_floor_estimate_inverse[0:PLOT_WINDOW_SIZE]\n",
    "\n",
    "# Calculating Spikes\n",
    "# Third Points\n",
    "time_array_subset_above_noise_floor_estimate = time_array_subset[\n",
    "    filtered_data_bandpass_subset > noise_floor_estimate_subset\n",
    "]\n",
    "filtered_data_bandpass_subset_above_noise_floor_estimate = (\n",
    "    filtered_data_bandpass_subset[\n",
    "        filtered_data_bandpass_subset > noise_floor_estimate_subset\n",
    "    ]\n",
    ")\n",
    "\n",
    "filtered_data_bandpass_subset_above_noise_floor_estimate_local_maximum_list = (\n",
    "    identify_potential_initial_spikes(\n",
    "        filtered_data_bandpass_subset_above_noise_floor_estimate\n",
    "    )\n",
    ")\n",
    "\n",
    "third_points = filtered_data_bandpass_subset_above_noise_floor_estimate[\n",
    "    filtered_data_bandpass_subset_above_noise_floor_estimate_local_maximum_list\n",
    "]\n",
    "time_third_points = time_array_subset_above_noise_floor_estimate[\n",
    "    filtered_data_bandpass_subset_above_noise_floor_estimate_local_maximum_list\n",
    "]\n",
    "\n",
    "# Second Points\n",
    "time_array_subset_below_noise_floor_estimate_inverse = time_array_subset[\n",
    "    filtered_data_bandpass_subset < noise_floor_estimate_inverse_subset\n",
    "]\n",
    "\n",
    "filtered_data_bandpass_subset_below_noise_floor_estimate_inverse = (\n",
    "    filtered_data_bandpass_subset[\n",
    "        filtered_data_bandpass_subset < noise_floor_estimate_inverse_subset\n",
    "    ]\n",
    ")\n",
    "filtered_data_bandpass_subset_below_noise_floor_estimate_inverse_local_minimum_list = (\n",
    "    identify_potential_initial_spikes(\n",
    "        filtered_data_bandpass_subset_below_noise_floor_estimate_inverse,\n",
    "        return_local_maximum=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "second_points = filtered_data_bandpass_subset_below_noise_floor_estimate_inverse[\n",
    "    filtered_data_bandpass_subset_below_noise_floor_estimate_inverse_local_minimum_list\n",
    "]\n",
    "t_second_points = time_array_subset_below_noise_floor_estimate_inverse[\n",
    "    filtered_data_bandpass_subset_below_noise_floor_estimate_inverse_local_minimum_list\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(36, 10))\n",
    "# Time Domain Signal Values\n",
    "plt.plot(\n",
    "    time_array[0:PLOT_WINDOW_SIZE],\n",
    "    filtered_data_bandpass[0:PLOT_WINDOW_SIZE],\n",
    "    color=list(mcolors.TABLEAU_COLORS.keys())[2],\n",
    "    linewidth=1,\n",
    "    label=\"Bandpass Filtered Data\",\n",
    ")\n",
    "plt.plot(\n",
    "    time_array[0:PLOT_WINDOW_SIZE],\n",
    "    noise_floor_estimate[0:PLOT_WINDOW_SIZE],\n",
    "    label=\"Noise Floor Estimate\",\n",
    "    color=\"orange\",\n",
    ")\n",
    "plt.plot(\n",
    "    time_array[0:PLOT_WINDOW_SIZE],\n",
    "    noise_floor_estimate_inverse[0:PLOT_WINDOW_SIZE],\n",
    "    label=\"Inverse of the Noise Floor Estimate\",\n",
    "    color=\"purple\",\n",
    ")\n",
    "\n",
    "# Thresholded Points\n",
    "plt.plot(\n",
    "    time_array_subset[local_maximum_list[0:PLOT_WINDOW_SIZE]],\n",
    "    filtered_data_bandpass_subset[local_maximum_list[0:PLOT_WINDOW_SIZE]],\n",
    "    \"o\",\n",
    "    color=list(mcolors.TABLEAU_COLORS.keys())[9],\n",
    "    label=\"Potential Initial Spikes\",\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    time_third_points,\n",
    "    third_points,\n",
    "    \"o\",\n",
    "    color=\"green\",\n",
    "    label=\"Potential Third Spike Points\",\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    t_second_points,\n",
    "    second_points,\n",
    "    \"o\",\n",
    "    color=\"yellow\",\n",
    "    label=\"Potential Second Spike Points\",\n",
    ")\n",
    "\n",
    "plt.axhline(y=0, color=\"black\")\n",
    "\n",
    "# Detected Spikes\n",
    "MAX_SPIKES_TO_PLOT = 10\n",
    "for SPIKE_NUMBER in range(0, MAX_SPIKES_TO_PLOT):\n",
    "    plt.plot(\n",
    "        time_array[spike_train_time_index_list[SPIKE_NUMBER]],\n",
    "        filtered_data_bandpass[spike_train_time_index_list[SPIKE_NUMBER]],\n",
    "        \"-\",\n",
    "        color=list(mcolors.TABLEAU_COLORS.keys())[3],\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"The First %i Detected Neural Spikes: Shown in Red\" % MAX_SPIKES_TO_PLOT)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKE_NUMBER = 1\n",
    "\n",
    "plt.plot(\n",
    "    time_array[spike_train_time_index_list[SPIKE_NUMBER]],\n",
    "    filtered_data_bandpass[spike_train_time_index_list[SPIKE_NUMBER]],\n",
    ")\n",
    "\n",
    "print(f\"Number of Points in detected spike: \", end=\"\")\n",
    "print(f\"{len(spike_train_time_index_list[SPIKE_NUMBER])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    Algorithm:\n",
    "    1. Create a third degree polynomial to fit the first detected spike.\n",
    "    2. Create a line of best fit to another detected spike using a third\n",
    "        degree polynomial.\n",
    "    3. Compare the difference between the polynomials. This should be a\n",
    "        difference in scale and shift. \n",
    "    4. Include residuals, the scale, & the shift needed to recreate the\n",
    "        waveform. The number of points should be inferred to be\n",
    "        equidistant. The scale and shift will differ based upon the\n",
    "        first detected spike. If this information is less than the\n",
    "        number of points total in the original spike, then use this as\n",
    "        a means of representing the waveform. Otherwise, use the\n",
    "        explicitly defined points. \n",
    "    5. Create a means of representing the encoding. Include a list of\n",
    "        compressed waveforms and a list of explicitly defined points.\n",
    "        Include identifiers of the length of the number of values in\n",
    "        each list before the list. This order is implied knowledge when\n",
    "        decoding. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Detected Spikes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = create_encoded_data(\n",
    "    sample_rate,\n",
    "    len(filtered_data_bandpass),\n",
    "    spike_train_time_index_list,\n",
    "    filtered_data_bandpass,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percent Reduction in file size\n",
    "print(\n",
    "    \"The original file size has been reduced by %0.2f%%. \"\n",
    "    % ((1 - sys.getsizeof(encoded_data) / sys.getsizeof(raw_neural_data)) * 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Metadata\n",
    "encoded_data\n",
    "encoded_data = deque(encoded_data)\n",
    "sample_rate = encoded_data.popleft()\n",
    "number_of_samples = encoded_data.popleft()\n",
    "\n",
    "# Construct the Time Array\n",
    "time_endpoint = number_of_samples / sample_rate\n",
    "time_array = np.arange(start=0, stop=time_endpoint, step=(1 / sample_rate))\n",
    "\n",
    "# Create the Amplitude Array\n",
    "amplitude_array = np.int16(np.zeros(len(time_array)))\n",
    "counter = 0\n",
    "while len(encoded_data) > 0:\n",
    "    counter += 1\n",
    "    amplitude_start_time_index = encoded_data.popleft()\n",
    "    if amplitude_start_time_index < 0:\n",
    "        print(amplitude_start_time_index)\n",
    "    spike_amplitudes = encoded_data.popleft()\n",
    "    if counter == 3378:\n",
    "        print(counter)\n",
    "    for amplitude_index, amplitude in enumerate(spike_amplitudes):\n",
    "        # if (amplitude_start_time_index + amplitude_index) == 49349:\n",
    "        #     print(amplitude)\n",
    "        amplitude_array[amplitude_start_time_index + amplitude_index] = amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALAR = 60\n",
    "\n",
    "PLOT_WINDOW_SHIFT = 10 * SCALAR\n",
    "PLOT_WINDOW_LENGTH = 10 * SCALAR\n",
    "# plt.plot(\n",
    "#     time_array[PLOT_WINDOW_SHIFT : PLOT_WINDOW_SHIFT + PLOT_WINDOW_LENGTH],\n",
    "#     amplitude_array[PLOT_WINDOW_SHIFT : PLOT_WINDOW_SHIFT + PLOT_WINDOW_LENGTH],\n",
    "#     linewidth=0.5,\n",
    "# )\n",
    "\n",
    "plt.plot(\n",
    "    time_array,\n",
    "    amplitude_array,\n",
    "    linewidth=0.5,\n",
    ")\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"Reconstructed Spike Train\")\n",
    "plt.legend([\"Neural Signal\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(amplitude_array, rate=sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_encoding_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
