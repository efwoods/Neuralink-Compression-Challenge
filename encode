#!/usr/bin/python3

import heapq
import pickle
import sys
from scipy.io import wavfile
import numpy as np
from signal_processing_utilities import process_signal


### Testing
def encode_rle(
    original_data_list: list,
    use_rle_locations=False,
    data_is_binary=False,
    UNSIGNED_INTEGER_CUTOFF_VALUE=65530,
):
    """This algorithm will search for contiguous values within the
       array. When the number_of_values_apriori_in_index_array is
       greater than the value 65530, the count is reduced by this value
       in order to prevent an overflow of an unsigned 16-bit integer.
       This allows for the data to be stored with 2 bytes when the
       format of the array is a known value in advance of decoding this
       format. The choice of integer 65530 is an arbitrary value less
       than that of the maximum value of an unsigned 16-bit integer
       (65536). In this body of work, the value 65530 is denoted as the
       UNSIGNED_INTEGER_CUTOFF_VALUE.

    Args:
        original_data_list (list): This is a list of integer values to
                                   be encoded.
        use_rle_locations (bool, optional): This is a flag which
                                            indicates whether a
                                            locations array will be
                                            implemented to identify
                                            where the run-length-encoded
                                            values exist within the
                                            compressed array. This is
                                            because the compressed array
                                            in this mode will not
                                            contain run-length-encoded
                                            values for values that have
                                            singular representations.

    Returns:
        index_array (list): This is the list of run length encoded
                            values.
        rle_locations_in_index_array (list): This is a list of locations
                                             of elements that are
                                             repeated that are present
                                             in the array of indices.
    """
    initial_index = 0
    second_index = 1
    frequency = 0
    index_array = []
    rle_locations_in_index_array = []
    number_of_values_apriori_in_index_array = 0

    while second_index < len(original_data_list):
        if original_data_list[initial_index] == original_data_list[second_index]:
            index_array.append(original_data_list[initial_index])
            if use_rle_locations:
                rle_locations_in_index_array.append(
                    number_of_values_apriori_in_index_array
                )
            frequency += 1  # This accounts for the first detected value.

            # continue searching the breadth of the array; increasing
            # the detected frequency of the value. This will break out
            # of the while loop when the first & second indices are not
            # equal. âˆ´, the first value will not be accounted for
            # because the while loop will be broken where the value
            # would have been incremented.
            while (
                second_index < len(original_data_list)
                and original_data_list[initial_index]
                == original_data_list[second_index]
            ):
                frequency += 1
                second_index += 1
            index_array.append(frequency)
            if use_rle_locations:
                if (
                    number_of_values_apriori_in_index_array
                    > UNSIGNED_INTEGER_CUTOFF_VALUE
                ):
                    number_of_values_apriori_in_index_array -= (
                        UNSIGNED_INTEGER_CUTOFF_VALUE
                    )
                # The code below is to skip over the indices that contain
                # the run-length-encoded value and the frequency of that
                # value.
                number_of_values_apriori_in_index_array += 2
        else:
            index_array.append(original_data_list[initial_index])
            if use_rle_locations:
                if (
                    number_of_values_apriori_in_index_array
                    > UNSIGNED_INTEGER_CUTOFF_VALUE
                ):
                    number_of_values_apriori_in_index_array -= (
                        UNSIGNED_INTEGER_CUTOFF_VALUE
                    )
            # The code below is to skip over the index that contains an
            # individual run-length-encoded value.
            if use_rle_locations:
                number_of_values_apriori_in_index_array += 1
            else:
                index_array.append(1)
        frequency = 0
        initial_index = second_index
        second_index += 1
    if original_data_list[-1] != index_array[-2]:
        index_array.append(original_data_list[-1])
        if use_rle_locations == False:
            index_array.append(1)
    return index_array, rle_locations_in_index_array


# RLE for bit compression
def rle_bit_compression(byte_string: bytes, compress=True, rle_locations=None):
    """This function will compress the byte string using
    run-length-encoding. It will create a rle_locations byte string to
    differentiate between frequency and value locations. When compress
    is set to true, rle_locations is non-optional. The return value
    established when compress is set to true is the expected input.
    This is labeled "rle_locations_compressed_byte_string". If
    "compress" is set to "False", the return values are the byte
    string object of the original byte_string input and the
    rle_locations as a list of integers. The rle_locations can be
    safely ignored.



    Args:
        byte_string (bytes): This is a bytes object of 0 and 1 values.
        compress (bool, optional): This is a flag to indicate if mode
                                   is to compress or decompress.
                                   Defaults to True.
        rle_locations (_type_, optional): These are the rle_locations
                                          that are used when
                                          decompressing. If "compress"
                                          is equal to "True", then this
                                          can safely be set to "None".
                                          Otherwise, this is a mandatory
                                          input. Defaults to None.

    Returns:
        rle_compressed_bytes (bytes): This is a byte string object of
                                       the compressed byte_string.
        rle_locations_compressed_byte_string (bytes): This is a
                                                      compressed byte
                                                      string object of
                                                      the rle_locations.
    """
    if compress:
        byte_string_str = str(byte_string).lstrip("b'").rstrip("'")
        # Convert byte string to string of bits

        initial_index = 0
        second_index = 1
        frequency = 0
        rle_compression = []
        rle_locations = []

        # RLE compessing the byte_string_str
        while second_index < len(byte_string_str):
            if byte_string_str[initial_index] == byte_string_str[second_index]:
                rle_compression.append(str(byte_string_str[initial_index]))
                frequency += 1
                while byte_string_str[initial_index] == byte_string_str[second_index]:
                    second_index += 1
                    frequency += 1
                    if second_index >= len(byte_string_str):
                        break
                rle_compression.append(str(frequency))
            else:
                rle_compression.append(byte_string_str[initial_index])
                rle_compression.append("x")
            frequency = 0
            initial_index = second_index
            second_index += 1
        # Accounting for the case of the frequency
        #   byte_string_str[second_index] not being accounted for if it
        #   is a unique value.
        # If non-unique, this will be handled by the frequency in the
        #   second while loop. Otherwise the second_index will be
        #   larger than the length of the byte_string_str, and the
        #   frequency of the individual value must be declared.

        if byte_string_str[-2] != byte_string_str[-1]:
            if rle_compression[-1] != "x":  # Redundancy to prevent error
                rle_compression.append("x")

        # verify rle_compression has captured all values:
        total = 0
        for index in range(0, len(rle_compression), 2):
            if rle_compression[index + 1] == "x":
                total += 1
            else:
                total = total + int(rle_compression[index + 1])

        # RLE locations array run-length-encoded compression:
        # -1 signifies the start of a run-length-encoding.
        # Otherwise the value is written individually.

        # Establishing RLE Locations
        for index in range(0, len(rle_compression)):
            rle_locations.append(len(rle_compression[index]))

        # Compression of RLE Locations
        initial_index = 0
        second_index = 1
        frequency = 0
        rle_locations_compressed = []
        while second_index < len(rle_locations):
            if rle_locations[initial_index] == rle_locations[second_index]:
                rle_locations_compressed.append(-1)
                rle_locations_compressed.append(rle_locations[initial_index])
                frequency += 1
                while rle_locations[initial_index] == rle_locations[second_index]:
                    second_index += 1
                    frequency += 1
                    if second_index >= len(rle_locations):
                        break
                rle_locations_compressed.append(frequency)
            else:
                rle_locations_compressed.append(rle_locations[initial_index])
            frequency = 0
            initial_index = second_index
            second_index += 1
        if rle_locations[-2] != rle_locations[-1]:
            rle_locations_compressed.append(rle_locations[-1])
        # RLE Locations Compressed to Byte String:
        rle_locations_compressed_byte_string_l = [
            rle_locations_compressed[index].to_bytes(2, "big", signed=True)
            for index in range(len(rle_locations_compressed))
        ]
        rle_locations_compressed_byte_string = b""
        for byte in rle_locations_compressed_byte_string_l:
            rle_locations_compressed_byte_string += byte

        rle_compression_join = "".join(rle_compression)
        rle_compressed_bytes = bytes(rle_compression_join, encoding="utf-8")

        return rle_compressed_bytes, rle_locations_compressed_byte_string
    else:
        rle_compressed_bytes = byte_string
        rle_locations_compressed_byte_string = rle_locations
        # RLE Locations Compressed Byte String Expansion:
        # int.from_bytes(, signed=True)
        rle_locations_compressed_byte_string_l = [
            rle_locations_compressed_byte_string[index : index + 2]
            for index in range(len(rle_locations_compressed_byte_string))
        ]

        rle_locations_compressed = []
        for index in range(0, len(rle_locations_compressed_byte_string_l), 2):
            rle_locations_compressed.append(
                int.from_bytes(
                    rle_locations_compressed_byte_string_l[index], signed=True
                )
            )

        # Expansion of RLE Locations Compressed:
        rle_locations = []
        index = 0

        while index < len(rle_locations_compressed):
            if rle_locations_compressed[index] != -1:
                rle_locations.append(rle_locations_compressed[index])
                index += 1
            else:
                index += 1
                rle_expanded_value_l = []
                rle_value = rle_locations_compressed[index]
                rle_value_frequency = rle_locations_compressed[index + 1]
                rle_expanded_value_l = [
                    rle_value for index in range(rle_value_frequency)
                ]
                rle_locations.extend(rle_expanded_value_l)
                index += 2

        # Original Byte Expansion
        rle_compressed_bytes_index = 0
        rle_location_index = 0
        rle_compressed_str_l = []

        # converting from bytes to int, but i need to go from bytes to string
        while rle_location_index < len(rle_locations):
            rle_compressed_str = (
                str(
                    rle_compressed_bytes[
                        rle_compressed_bytes_index : rle_compressed_bytes_index
                        + rle_locations[rle_location_index]
                    ],
                )
                .lstrip("b'")
                .rstrip("'")
            )
            rle_compressed_str_l.append(rle_compressed_str)

            rle_compressed_bytes_index += rle_locations[rle_location_index]
            rle_location_index += 1

        # Expand rle_compressed_int_l to a string
        byte_string_str = ""
        index = 0
        while index < len(rle_compressed_str_l):
            byte_string_str_subset_value = rle_compressed_str_l[index]
            byte_string_str_subset_value_frequency = rle_compressed_str_l[index + 1]
            if byte_string_str_subset_value_frequency != "x":
                byte_string_str_subset_l = [
                    byte_string_str_subset_value
                    for value in range(int(byte_string_str_subset_value_frequency))
                ]
                byte_string_str_subset_str = "".join(byte_string_str_subset_l)
                byte_string_str += byte_string_str_subset_str
                index += 2
            else:
                byte_string_str += byte_string_str_subset_value
                index += 2

        # Convert String type to original byte string
        byte_string = bytes(byte_string_str, encoding="utf-8")
        return byte_string, rle_locations


###


class Node:
    """Purpose: The Node class is used to sort the freqencies of the
    hexadecimal values into a binary tree. The binary tree is
    then used to identify a binary mapping that uniquely
    represents each hexadecimal byte-pair. This is the atomic
    unit of the Huffman encoding technique.
    """

    def __init__(self, freq, data, left=None, right=None):
        self.freq = freq
        self.data = data
        self.left = left
        self.right = right
        self.code = ""

    def __lt__(self, nxt):
        return self.freq < nxt.freq


def create_node_mapping_dictionary(node, val="", node_mapping_dict={}):
    """Creates a mapping of unique binary strings to unique bytes of
           pairs of hexidecimal values found within the input wave file.

    Args:
        node (Node): This is a node of class Node. It is used to build
                     the binary tree.
        val (str, optional): This is the huffman code that is being
                             built into the unique representation of the
                             hexadecimal pair. Defaults to ''.
        node_mapping_dict (dict, optional): This is the dictionary that
                                          contains the mapping of
                                          hexadecimal values to unique
                                          binary string representations.
                                          Defaults to {}.

    Returns:
        bytes: This function returns the bytes of the wave file that was
               read.
    """
    # Is this value a string or a
    newVal = val + str(node.code)
    # if node is not an edge node, traverse
    if node.left:
        create_node_mapping_dictionary(node.left, newVal, node_mapping_dict)
    if node.right:
        create_node_mapping_dictionary(node.right, newVal, node_mapping_dict)
    if not node.left and not node.right:
        node_mapping_dict[node.data] = newVal
        # print(f"{node.data} -> {newVal}")
    return node_mapping_dict


def determine_hex_freq(input_wav):
    """This function determines how frequent a hexadecimal pair of
        values occurs within a string of bytes.

    Args:
        input_wav (bytes): This is the string of bytes of the wav file
                           that was read into memory.

    Returns:
        sorted_hex_freq_dictionary: This function returns a dictionary
                                    of hexpairs which are mapped to
                                    frequency of occurence in the input
                                    wave file.
    """
    input_wav_hex = input_wav.hex()
    hex_freq_dictionary = {}
    for digit_position in range(0, len(input_wav.hex()), 2):
        current_hex_pair = (
            input_wav_hex[digit_position] + input_wav_hex[digit_position + 1]
        )
        try:
            hex_freq_dictionary[current_hex_pair] += 1
        except KeyError:
            hex_freq_dictionary[current_hex_pair] = 1
    sorted_hex_freq_dictionary = dict(
        sorted(hex_freq_dictionary.items(), key=lambda x: x[1])
    )
    return sorted_hex_freq_dictionary


def convertHexToBit(input_wav, node_mapping_dict):
    """This function uses a dictionary of node mappings to convert
          the hexadecimal representation of the of the input wave file
          to a string of bits. This representation is a compressed form
          of the hexadecimal representation of the input wave file.

    Args:
        input_wav (bytes): This is the path of the file to be read into
                           memory.
        node_mapping_dict (dict): This is the dictionary mapping bits to
                                the hexadecimal representation of the
                                input wav file.

    Returns:
        bit_string: This is the string of bits that will be written to
                   the output file.
        lenend_zero_padding: This is the number of zeroes that have been
                             padded onto the end of the bit string to
                             make a complete set of bytes.
    """
    hex_input_wav = input_wav.hex()
    bit_string = ""
    for index in range(0, len(hex_input_wav), 2):
        hex_pair = hex_input_wav[index] + hex_input_wav[index + 1]
        bit_string += node_mapping_dict[hex_pair]
    end_zero_padding = "0" * (8 - (len(bit_string) % 8))
    bit_string += end_zero_padding
    len_end_zero_padding = len(end_zero_padding)
    return bit_string, len_end_zero_padding


def create_byte_string(
    node_mapping_dict,
    bit_string,
    end_zero_padding,
):
    """This function writes the encoded outputfile.

    Args:
        node_mapping_dict (dict): This is the dictionary which maps each
                                  hexadecimal representation of the
                                  bytes of the input wave file to a
                                  string of bits whose length is
                                  depended on frequency of the
                                  hexadecimal pair.
        bit_string (str): This is the string of bits that is
                            interpreted from the original input wave
                            file and parsed using the node_mapping_dict.
        end_zero_padding (str): This is the number of zeroes that are
                                 padded to the end of the bit_string to
                                 create a full set of bytes to be
                                 written to the output data file.
    Returns:
        byte_string (bytes): This function returns a bytes object of the
                             compressed data.

    Notes:
        The encoding is the node_mapping_dictionary written as bytes, the
        encoded data as bytes, the indices of the start and end of each
        data portion as mentioned here, and the size in bytes of the
        indices. The last index of the indices array contains the value
        of the number of zeros that the encoded data is padded with.
        This is because the last index would be the length of the
        encoded data file, but this information can be interpreted
        otherwise. To decode this file, read the last byte of the file,
        use this information to calculate the position of the pickled
        indices array, deserialize this section of the file, then use
        the indices and the knowledge of the order of the storage of
        this information to deserialize and read the bytes. Finally,
        convert the encoded bytes into the original format using the
        node mapping dictionary to write the hex representation of the
        encoded information.
    """
    num_bytes = 1
    byteorder = "big"
    indices = []
    byte_string = b""
    node_mapping_dict_keys_list = list(node_mapping_dict.keys())
    node_mapping_dict_values_list = list(node_mapping_dict.values())

    # Node Mapping Dictionary Keys appended to byte_string:
    node_mapping_dict_keys_list_byte_string_l = [
        bytes(node_mapping_dict_keys_list[index], encoding="utf-8")
        for index in range(len(node_mapping_dict_keys_list))
    ]

    for key_value in node_mapping_dict_keys_list_byte_string_l:
        byte_string += key_value

    # Node Mapping Dictionary Keys: indices[0]
    indices.append(len(byte_string))

    # Node Mapping Dictionary Values appended to byte_string:
    node_mapping_dict_values_list_byte_string_l = [
        bytes(node_mapping_dict_values_list[index], encoding="utf-8")
        for index in range(len(node_mapping_dict_values_list))
    ]

    node_mapping_dict_values_byte_string = b""
    for value_bytes in node_mapping_dict_values_list_byte_string_l:
        node_mapping_dict_values_byte_string += value_bytes

    (
        rle_compressed_node_mapping_dictionary_values_bytes,
        rle_locations_compressed_byte_string,
    ) = rle_bit_compression(byte_string=node_mapping_dict_values_byte_string)

    byte_string += rle_compressed_node_mapping_dictionary_values_bytes

    # Node Mapping Dictionary Values (rle_compressed): indices[1]
    indices.append(len(byte_string))

    # Node Mapping Dictionary Values RLE Compressed Indices (rle_compressed): indices[2]
    byte_string += rle_locations_compressed_byte_string
    indices.append(len(byte_string))

    # Run-Length-Encoding the node mapping dictionary value lengths
    node_mapping_dict_values_indices_length_list = [
        len(node_mapping_dict_values_list[index])
        for index in range(len(node_mapping_dict_values_list))
    ]
    # This information is non-binary âˆ´ encode_rle is used as encoding.
    # node_mapping_dict_values_indices_length_list_compresed has a known
    # format index pair of "value, frequency" for each "index, index+1"
    # within the array.
    node_mapping_dict_values_indices_length_list_compresed, rle_locations = encode_rle(
        node_mapping_dict_values_indices_length_list
    )

    node_mapping_dict_values_indices_length_compressed_byte_string_l = [
        node_mapping_dict_values_indices_length_list_compresed[index].to_bytes(
            1, byteorder="big"
        )
        for index in range(len(node_mapping_dict_values_indices_length_list_compresed))
    ]

    for byte in node_mapping_dict_values_indices_length_compressed_byte_string_l:
        byte_string += byte

    # Node Mapping Dictionary Values Indices
    #   (rle_compressed via encode_rle): indices[3]
    indices.append(len(byte_string))

    for index in range(0, len(bit_string), 8):
        byte_to_write = bit_string[index : index + 8]
        int_of_byte_to_write = int(byte_to_write, base=2)
        byte_string += int_of_byte_to_write.to_bytes(num_bytes, byteorder)

    # This is the length of the huffman encoded string of bits stored as
    # rle bytes: indices[4]
    indices.append(len(byte_string))

    # This is the number of zeros that have been padded to the ultimate
    # byte_string index in order to make it equal to a byte.
    # end_zero_padding: indices[5]
    indices.append(end_zero_padding)

    bytes_indices_list = [index.to_bytes(4, "big") for index in indices]
    for byte in bytes_indices_list:
        byte_string += byte
    bytes_indices_size = 4 * len(bytes_indices_list)

    # The line of code below is presuming the
    # "bytes_indices_size" is < 256
    byte_string += bytes_indices_size.to_bytes(2, byteorder=byteorder)
    return byte_string


def huffman_encoding(
    input_data: np.ndarray,
    compressed_file_path: str = None,
):
    """Main method to drive the encoding operation implementing huffman
    encoding.

    Args:
        input_data (np.ndarray): This is the input wave file
                                           as a numpy array. If this
                                           input is given, the data will
                                           be converted to bytes.
        compressed_file_path (str, optional): This is the string of the
                                              location
                                              of the output compressed
                                              file.
                                              Defaults to None.

    Returns:
        node_mapping_dict (dict): This is the dictionary containing
                                hexadecimal keys and their corresponding
                                binary string values.
        bit_string (str): This is the string of bits that represent the
                         huffman encoded data.
        end_zero_padding (int): This is the integer that indicates how
                              many zeros have been added to the bit
                              string to make the length evenly divisible
                              by eight such that each eight bits may be
                              converted into individual bytes.
    """

    if compressed_file_path == None:
        compressed_file_path = sys.argv[2]

    sorted_hex_freq_dict = determine_hex_freq(
        input_data if type(input_data) == bytes else input_data.tobytes()
    )
    hex_freq_values = list(sorted_hex_freq_dict.values())
    hex_freq_keys = list(sorted_hex_freq_dict.keys())

    # Create a list of nodes
    nodes = []
    for item in range(len(hex_freq_keys)):
        heapq.heappush(nodes, Node(hex_freq_values[item], hex_freq_keys[item]))

    # Build the node tree
    while len(nodes) > 1:
        left = heapq.heappop(nodes)
        right = heapq.heappop(nodes)
        left.code = 0
        right.code = 1
        newNode = Node(
            left.freq + right.freq, left.data + right.data, left=left, right=right
        )
        heapq.heappush(nodes, newNode)
    node_mapping_dict = create_node_mapping_dictionary(
        nodes[0], val="", node_mapping_dict={}
    )

    # The hexadecimal representation of the bytes of the input wave file
    # is converted to a string of bits to write
    bit_string, end_zero_padding = convertHexToBit(
        input_data if type(input_data) == bytes else input_data.tobytes(),
        node_mapping_dict,
    )

    return node_mapping_dict, bit_string, end_zero_padding


def read_file(file: str = None, compressed_file_path: str = None):
    """This function reads a file and returns the sample rate and the
    waveform of the file to be processed and compressed as well as the
    path of which to compress the file.

    Args:
        file (str, optional): This is the name of the file to be
                              compressed. The format of the string is
                              expected to be "dir/*.wav" for example.
                              This is set to default as "None" so as to
                              enable the function to operate with a
                              command line input when no file path is
                              passed to the main method or to enable the
                              main method to be tested with custom
                              input. Defaults to None.
        compressed_file_path (str, optional): This is the string of the
                                              location of the output
                                              compressed file. Defaults
                                              to None.

    Returns:
        sample_rate (int): This is the rate of the sample.
        input_wav (array): This is the waveform representation of the
                           audio.
        compressed_file_path (str): This is the path of which to
                                    compress the file.
    """
    if file == None:
        file = sys.argv[1]

    if compressed_file_path == None:
        compressed_file_path = sys.argv[2]

    print("file: {}".format(file))
    print("compressed_file_path: {}".format(compressed_file_path))

    sample_rate, input_wav = wavfile.read(file)
    return sample_rate, input_wav, compressed_file_path


def create_huffman_encoded_file():
    """This driver function will read the data before huffman encoding
    the data and writing the resulting string of bytes to a file."""

    sample_rate, input_wav, compressed_file_path = read_file()
    node_mapping_dict, bit_string, end_zero_padding = huffman_encoding(
        input_data=input_wav, compressed_file_path=compressed_file_path
    )
    byte_string = create_byte_string(node_mapping_dict, bit_string, end_zero_padding)
    process_signal.write_file_bytes(
        file_path=compressed_file_path, data_bytes=byte_string
    )


def implement_spike_detection_module_and_huffman_encode_file():
    """This driver function will read data, preprocess the data, detect neural
    spikes, create an object containing only the detected spikes,
    convert this object to a string of bytes, huffman encode those
    bytes, and write the huffman encoded representation of the bytes to
    a file."""

    # Read Data
    sample_rate, input_wav, compressed_file_path = read_file()

    # Preprocess Data & Detect Spikes
    filtered_data_bandpass = process_signal.preprocess_signal(
        raw_neural_signal=input_wav, sample_rate=sample_rate
    )
    spike_train_time_index_list = process_signal.detect_neural_spikes(
        filtered_data_bandpass
    )
    encoded_data = process_signal.create_encoded_data(
        sample_rate=sample_rate,
        number_of_samples=len(filtered_data_bandpass),
        spike_train_time_index_list=spike_train_time_index_list,
        neural_data=filtered_data_bandpass,
    )

    encoded_data_byte_string = process_signal.convert_encoded_data_to_byte_string(
        encoded_data
    )

    byte_string = huffman_encoding(
        input_data=encoded_data_byte_string, compressed_file_path=compressed_file_path
    )
    process_signal.write_file_bytes(
        file_path=compressed_file_path, data_bytes=byte_string
    )


def compress(file: str):
    """This function accepts a file path to compress. It will read data,
    preprocess the data, detect neural spikes, create an object
    containing only the detected spikes, convert this object to a string
    of bytes, huffman encode those bytes, and will return a bytes object
    containing the compressed data.

    Args:
        file (str): This is the path to the file to be compressed.
    """
    sample_rate, input_wav = wavfile.read(file)
    filtered_data_bandpass = process_signal.preprocess_signal(
        raw_neural_signal=input_wav, sample_rate=sample_rate
    )
    spike_train_time_index_list = process_signal.detect_neural_spikes(
        filtered_data_bandpass
    )
    encoded_data = process_signal.create_encoded_data(
        sample_rate=sample_rate,
        number_of_samples=len(filtered_data_bandpass),
        spike_train_time_index_list=spike_train_time_index_list,
        neural_data=filtered_data_bandpass,
    )
    encoded_data_byte_string = process_signal.convert_encoded_data_to_byte_string(
        encoded_data
    )
    node_mapping_dict, bit_string, end_zero_padding = huffman_encoding(
        input_data=encoded_data_byte_string, compressed_file_path=(file + ".brainwire")
    )

    byte_string = create_byte_string(node_mapping_dict, bit_string, end_zero_padding)
    return byte_string


def main():
    """This is the main driver of the code."""
    # create_huffman_encoded_file()
    implement_spike_detection_module_and_huffman_encode_file()


if __name__ == "__main__":
    main()
