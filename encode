#!/usr/bin/python3

import heapq
import pickle
import sys
from scipy.io import wavfile
import numpy as np
from signal_processing_utilities import process_signal


class Node:
    """Purpose: The Node class is used to sort the freqencies of the
    hexadecimal values into a binary tree. The binary tree is
    then used to identify a binary mapping that uniquely
    represents each hexadecimal byte-pair. This is the atomic
    unit of the Huffman encoding technique.
    """

    def __init__(self, freq, data, left=None, right=None):
        self.freq = freq
        self.data = data
        self.left = left
        self.right = right
        self.code = ""

    def __lt__(self, nxt):
        return self.freq < nxt.freq


def createNodeMappingDictionary(node, val="", nodeMappingDict={}):
    """Creates a mapping of unique binary strings to unique bytes of
           pairs of hexidecimal values found within the input wave file.

    Args:
        node (Node): This is a node of class Node. It is used to build
                     the binary tree.
        val (str, optional): This is the huffman code that is being
                             built into the unique representation of the
                             hexadecimal pair. Defaults to ''.
        nodeMappingDict (dict, optional): This is the dictionary that
                                          contains the mapping of
                                          hexadecimal values to unique
                                          binary string representations.
                                          Defaults to {}.

    Returns:
        bytes: This function returns the bytes of the wave file that was
               read.
    """
    newVal = val + str(node.code)
    # if node is not an edge node, traverse
    if node.left:
        createNodeMappingDictionary(node.left, newVal, nodeMappingDict)
    if node.right:
        createNodeMappingDictionary(node.right, newVal, nodeMappingDict)
    if not node.left and not node.right:
        nodeMappingDict[node.data] = newVal
        # print(f"{node.data} -> {newVal}")
    return nodeMappingDict


def determine_hex_freq(input_wav):
    """This function determines how frequent a hexadecimal pair of
        values occurs within a string of bytes.

    Args:
        input_wav (bytes): This is the string of bytes of the wav file
                           that was read into memory.

    Returns:
        sorted_hex_freq_dictionary: This function returns a dictionary
                                    of hexpairs which are mapped to
                                    frequency of occurence in the input
                                    wave file.
    """
    input_wav_hex = input_wav.hex()
    hex_freq_dictionary = {}
    for digit_position in range(0, len(input_wav.hex()), 2):
        current_hex_pair = (
            input_wav_hex[digit_position] + input_wav_hex[digit_position + 1]
        )
        try:
            hex_freq_dictionary[current_hex_pair] += 1
        except KeyError:
            hex_freq_dictionary[current_hex_pair] = 1
    sorted_hex_freq_dictionary = dict(
        sorted(hex_freq_dictionary.items(), key=lambda x: x[1])
    )
    return sorted_hex_freq_dictionary


def convertHexToBit(input_wav, nodeMappingDict):
    """This function uses a dictionary of node mappings to convert
          the hexadecimal representation of the of the input wave file
          to a string of bits. This representation is a compressed form
          of the hexadecimal representation of the input wave file.

    Args:
        input_wav (bytes): This is the path of the file to be read into
                           memory.
        nodeMappingDict (dict): This is the dictionary mapping bits to
                                the hexadecimal representation of the
                                input wav file.

    Returns:
        bitString: This is the string of bits that will be written to
                   the output file.
        lenEndZeroPadding: This is the number of zeroes that have been
                             padded onto the end of the bit string to
                             make a complete set of bytes.
    """
    hex_input_wav = input_wav.hex()
    bitString = ""
    for index in range(0, len(hex_input_wav), 2):
        hex_pair = hex_input_wav[index] + hex_input_wav[index + 1]
        bitString += nodeMappingDict[hex_pair]
    endZeroPadding = "0" * (8 - (len(bitString) % 8))
    bitString += endZeroPadding
    lenEndZeroPadding = len(endZeroPadding)
    return bitString, lenEndZeroPadding


def write_file(
    compressed_file_path,
    nodeMappingDict,
    bitString,
    endZeroPadding,
    use_pickle_file_format=False,
):
    """This function writes the encoded outputfile.

    Args:
        compressed_file_path (str): This is the path to which to write
                                    the compressed file.
        nodeMappingDict (dict): This is the dictionary which maps each
                                  hexadecimal representation of the
                                  bytes of the input wave file to a
                                  string of bits whose length is
                                  depended on frequency of the
                                  hexadecimal pair.
        bitString (str): This is the string of bits that is
                            interpreted from the original input wave
                            file and parsed using the nodeMappingDict.
        endZeroPadding (str): This is the number of zeroes that are
                                 padded to the end of the bitString to
                                 create a full set of bytes to be
                                 written to the output data file.
        use_pickle_file_format (bool, optional): This is an indicator
                                                 which will use
                                                 pickling on set to
                                                 'True'.
                                                 Otherwise, manual
                                                 writing of bytes will
                                                 be implemented.
                                                 Defaults to 'False'.
    Returns:
        byte_string (bytes): This function returns a bytes object of the
                             compressed data.

    Notes:
        The encoding is the pickled nodeMappingDictionary, the encoded
        data as bytes, the indices of the start and end of each data
        portion as mentioned here, and the size in bytes of the
        indices. The last index of the indices array contains the value
        of the number of zeros that the encoded data is padded with.
        This is because the last index would be the length of the
        encoded data file, but this information can be interpreted
        otherwise. To decode this file, read the last byte of the file,
        use this information to calculate the position of the pickled
        indices array, deserialize this section of the file, then use
        the indices and the knowledge of the order of the storage of
        this information to deserialize and read the bytes. Finally,
        convert the encoded bytes into the original format using the
        node mapping dictionary to write the hex representation of the
        encoded information.
    """
    with open(compressed_file_path, "wb+") as file:
        num_bytes = 1
        byteorder = "big"
        indices = []
        byte_string = b""
        indices.append(file.tell())

        # Debugging
        latent_byte_string = b""
        written_file_size_l = []

        if use_pickle_file_format:
            file.write(pickle.dumps(nodeMappingDict))
        else:
            node_mapping_dict_list = list(nodeMappingDict.items())
            for index in range(0, len(node_mapping_dict_list)):
                byte = int(node_mapping_dict_list[index][0], base=16)
                byte = byte.to_bytes()

                # latent_byte_string = bytes(
                #     node_mapping_dict_list[index][0], encoding="utf-8"
                # )
                latent_byte_string = byte
                byte_string += latent_byte_string
                written_file_size_l.append(
                    # file.write(
                    #     bytes(node_mapping_dict_list[index][0], encoding="utf-8")
                    # )
                    file.write(byte)
                )

                latent_byte_string = bytes(
                    node_mapping_dict_list[index][1], encoding="utf-8"
                )
                byte_string += latent_byte_string

                # This could be optimized to write a rle of the bit-string:
                # bytes(node_mapping_dict_list[index][1], encoding="utf-8")
                written_file_size_l.append(
                    file.write(
                        bytes(node_mapping_dict_list[index][1], encoding="utf-8")
                    )
                )
        indices.append(file.tell())
        for index in range(0, len(bitString), 8):
            byte_to_write = bitString[index : index + 8]
            int_of_byte_to_write = int(byte_to_write, 2)

            latent_byte_string = b""
            latent_byte_string = int_of_byte_to_write.to_bytes(num_bytes, byteorder)
            byte_string += latent_byte_string

            written_file_size_l.append(
                file.write(int_of_byte_to_write.to_bytes(num_bytes, byteorder))
            )
        indices.append(file.tell())
        indices.append(endZeroPadding)
        if use_pickle_file_format:
            bytes_indices = file.write(pickle.dumps(indices))

            # This indicates the number of bytes that were written to the
            # file with respect to the size in bytes of the number of
            # indices.
            file.write(bytes_indices.to_bytes(1, byteorder=byteorder))
        else:
            bytes_indices_list = [
                file.write(index.to_bytes(4, "big")) for index in indices
            ]
            written_file_size_l.append(sum(bytes_indices_list))

            # bytes_indices_list = [index.to_bytes(4, "big") for index in indices]
            # for index in bytes_indices_list:
            #     latent_byte_string += bytes_indices_list[index]
            #     byte_string = latent_byte_string

            bytes_indices_size = sum(bytes_indices_list)

            latent_byte_string = bytes_indices_size.to_bytes(1, byteorder=byteorder)
            byte_string += latent_byte_string

            # The line of code below is presuming the
            # "bytes_indices_size" is < 256
            written_file_size_l.append(
                file.write(bytes_indices_size.to_bytes(1, byteorder=byteorder))
            )

            return byte_string


def huffman_encoding(
    input_data: np.ndarray,
    compressed_file_path: str = None,
):
    """Main method to drive the encoding operation implementing huffman
    encoding.

    Args:
        input_data (np.ndarray): This is the input wave file
                                           as a numpy array. If this
                                           input is given, the data will
                                           be converted to bytes.
        compressed_file_path (str, optional): This is the string of the
                                              location
                                              of the output compressed
                                              file.
                                              Defaults to None.
    """

    if compressed_file_path == None:
        compressed_file_path = sys.argv[2]

    sorted_hex_freq_dict = determine_hex_freq(
        input_data if type(input_data) == bytes else input_data.tobytes()
    )
    hex_freq_values = list(sorted_hex_freq_dict.values())
    hex_freq_keys = list(sorted_hex_freq_dict.keys())

    # Create a list of nodes
    nodes = []
    for item in range(len(hex_freq_keys)):
        heapq.heappush(nodes, Node(hex_freq_values[item], hex_freq_keys[item]))

    # Build the node tree
    while len(nodes) > 1:
        left = heapq.heappop(nodes)
        right = heapq.heappop(nodes)
        left.code = 0
        right.code = 1
        newNode = Node(
            left.freq + right.freq, left.data + right.data, left=left, right=right
        )
        heapq.heappush(nodes, newNode)
    nodeMappingDict = createNodeMappingDictionary(nodes[0], val="", nodeMappingDict={})

    # The hexadecimal representation of the bytes of the input wave file
    # is converted to a string of bits to write
    bitString, endZeroPadding = convertHexToBit(
        input_data if type(input_data) == bytes else input_data.tobytes(),
        nodeMappingDict,
    )

    # The bits are written by using single bytes of integers
    byte_string = write_file(
        compressed_file_path,
        nodeMappingDict,
        bitString,
        endZeroPadding,
        use_pickle_file_format=False,
    )

    return byte_string


def read_file(file: str = None, compressed_file_path: str = None):
    """This function reads a file and returns the sample rate and the
    waveform of the file to be processed and compressed as well as the
    path of which to compress the file.

    Args:
        file (str, optional): This is the name of the file to be
                              compressed. The format of the string is
                              expected to be "dir/*.wav" for example.
                              This is set to default as "None" so as to
                              enable the function to operate with a
                              command line input when no file path is
                              passed to the main method or to enable the
                              main method to be tested with custom
                              input. Defaults to None.
        compressed_file_path (str, optional): This is the string of the
                                              location of the output
                                              compressed file. Defaults
                                              to None.

    Returns:
        sample_rate (int): This is the rate of the sample.
        input_wav (array): This is the waveform representation of the
                           audio.
        compressed_file_path (str): This is the path of which to
                                    compress the file.
    """
    if file == None:
        file = sys.argv[1]

    if compressed_file_path == None:
        compressed_file_path = sys.argv[2]

    print("file: {}".format(file))
    print("compressed_file_path: {}".format(compressed_file_path))

    sample_rate, input_wav = wavfile.read(file)
    return sample_rate, input_wav, compressed_file_path


def create_huffman_encoded_file():
    """This driver function will read the data before huffman encoding
    the data and writing the resulting string of bytes to a file."""

    sample_rate, input_wav, compressed_file_path = read_file()
    huffman_encoding(input_data=input_wav, compressed_file_path=compressed_file_path)


def implement_spike_detection_module_and_huffman_encode_file():
    """This driver function will read data, preprocess the data, detect neural
    spikes, create an object containing only the detected spikes,
    convert this object to a string of bytes, huffman encode those
    bytes, and write the huffman encoded representation of the bytes to
    a file."""

    # Read Data
    sample_rate, input_wav, compressed_file_path = read_file()

    # Preprocess Data & Detect Spikes
    filtered_data_bandpass = process_signal.preprocess_signal(
        raw_neural_signal=input_wav, sample_rate=sample_rate
    )
    spike_train_time_index_list = process_signal.detect_neural_spikes(
        filtered_data_bandpass
    )
    encoded_data = process_signal.create_encoded_data(
        sample_rate=sample_rate,
        number_of_samples=len(filtered_data_bandpass),
        spike_train_time_index_list=spike_train_time_index_list,
        neural_data=filtered_data_bandpass,
    )

    encoded_data_byte_string = process_signal.convert_encoded_data_to_byte_string(
        encoded_data
    )

    huffman_encoding(input_data=input_wav, compressed_file_path=compressed_file_path)


def compress(file: str):
    """This function accepts a file path to compress. It will read data,
    preprocess the data, detect neural spikes, create an object
    containing only hte detected spikes, convert this object to a string
    of bytes, huffman encode those bytes, and will return a bytes object
    containing the compressed data.

    Args:
        file (str): This is the path to the file to be compressed.
    """
    sample_rate, input_wav = wavfile.read(file)
    filtered_data_bandpass = process_signal.preprocess_signal(
        raw_neural_signal=input_wav, sample_rate=sample_rate
    )
    spike_train_time_index_list = process_signal.detect_neural_spikes(
        filtered_data_bandpass
    )
    encoded_data = process_signal.create_encoded_data(
        sample_rate=sample_rate,
        number_of_samples=len(filtered_data_bandpass),
        spike_train_time_index_list=spike_train_time_index_list,
        neural_data=filtered_data_bandpass,
    )
    encoded_data_byte_string = process_signal.convert_encoded_data_to_byte_string(
        encoded_data
    )
    byte_string = huffman_encoding(
        input_data=encoded_data_byte_string, compressed_file_path=(file + ".brainwire")
    )
    return byte_string


def main():
    """This is the main driver of the code."""
    # create_huffman_encoded_file()
    implement_spike_detection_module_and_huffman_encode_file()


if __name__ == "__main__":
    main()
